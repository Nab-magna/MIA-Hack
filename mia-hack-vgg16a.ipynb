{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913030f9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T09:46:56.070452Z",
     "iopub.status.busy": "2025-04-07T09:46:56.069899Z",
     "iopub.status.idle": "2025-04-07T09:47:06.096317Z",
     "shell.execute_reply": "2025-04-07T09:47:06.095211Z"
    },
    "papermill": {
     "duration": 10.032486,
     "end_time": "2025-04-07T09:47:06.098639",
     "exception": false,
     "start_time": "2025-04-07T09:46:56.066153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\r\n",
      "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\r\n",
      "Collecting fire (from medmnist)\r\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\r\n",
      "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\r\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\r\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->medmnist) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->medmnist) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->medmnist) (2024.2.0)\r\n",
      "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\r\n",
      "Building wheels for collected packages: fire\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=f2aab55fc1026af8ae6c73066d5763d6df5887259950734b66e836300d84f0a3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\r\n",
      "Successfully built fire\r\n",
      "Installing collected packages: fire, medmnist\r\n",
      "Successfully installed fire-0.7.0 medmnist-3.0.2\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba13b6ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:47:06.106020Z",
     "iopub.status.busy": "2025-04-07T09:47:06.105742Z",
     "iopub.status.idle": "2025-04-07T09:47:29.691542Z",
     "shell.execute_reply": "2025-04-07T09:47:29.690514Z"
    },
    "papermill": {
     "duration": 23.590714,
     "end_time": "2025-04-07T09:47:29.692835",
     "exception": false,
     "start_time": "2025-04-07T09:47:06.102121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenodo.org/records/10519652/files/octmnist.npz?download=1 to /root/.medmnist/octmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54.9M/54.9M [00:07<00:00, 6.87MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenodo.org/records/10519652/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.17M/4.17M [00:00<00:00, 7.30MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenodo.org/records/10519652/files/retinamnist.npz?download=1 to /root/.medmnist/retinamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.29M/3.29M [00:00<00:00, 6.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenodo.org/records/10519652/files/breastmnist.npz?download=1 to /root/.medmnist/breastmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560k/560k [00:00<00:00, 4.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loader1 size:1623\n",
      "Train_loader2 size:1623\n",
      "Using downloaded and verified file: /root/.medmnist/octmnist.npz\n",
      "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /root/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
      "Eval_loader size:69\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import random_split\n",
    "from medmnist import OCTMNIST, PneumoniaMNIST, RetinaMNIST,BreastMNIST\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean for RGB\n",
    "                         [0.229, 0.224, 0.225])  # ImageNet std for RGB\n",
    "])\n",
    "\n",
    "# Custom Dataset class to handle merged datasets and apply offsets\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datasets, offsets, transform=None):\n",
    "        self.datasets = datasets\n",
    "        self.offsets = offsets\n",
    "        self.transform = transform\n",
    "        self.merged_samples = self._merge_datasets()\n",
    "\n",
    "    def _merge_datasets(self):\n",
    "        samples = []\n",
    "        for name, dataset in self.datasets.items():\n",
    "            offset = self.offsets[name]\n",
    "            samples.extend(self.offset_dataset(dataset, offset))\n",
    "        return samples\n",
    "\n",
    "    def offset_dataset(self, dataset, offset):\n",
    "        new_samples = []\n",
    "        for x, y in dataset:\n",
    "            new_y = torch.tensor([y[0] + offset])\n",
    "            new_samples.append((x, new_y))\n",
    "        return new_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.merged_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.merged_samples[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "# Load the datasets\n",
    "datasets = {\n",
    "    'oct': OCTMNIST(split='train', transform=None, download=True),\n",
    "    'pneu': PneumoniaMNIST(split='train', transform=None, download=True),\n",
    "    'retina': RetinaMNIST(split='train', transform=None, download=True),\n",
    "    'breast': BreastMNIST(split='train', transform=None, download=True)\n",
    "}\n",
    "\n",
    "# Set offsets to distinguish different classes in each dataset\n",
    "offsets = {'oct': 0, 'pneu': 4, 'retina': 6, 'breast': 11}\n",
    "\n",
    "# Create the custom dataset and apply transformations\n",
    "custom_dataset = CustomDataset(datasets, offsets, transform=transform)\n",
    "\n",
    "len1=len(custom_dataset)//2\n",
    "len2=len(custom_dataset) - len1\n",
    "\n",
    "first_half, second_half = random_split(custom_dataset, [len1, len2])\n",
    "loader1 = DataLoader(first_half, batch_size=32, shuffle=True)\n",
    "loader2 = DataLoader(second_half, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Train_loader1 size:{len(loader1)}\")\n",
    "print(f\"Train_loader2 size:{len(loader2)}\")\n",
    "#Creating the val datasets \n",
    "test_datasets = {\n",
    "    'oct': OCTMNIST(split='test', transform=None, download=True),\n",
    "    'pneu': PneumoniaMNIST(split='test', transform=None, download=True),\n",
    "    'retina': RetinaMNIST(split='test', transform=None, download=True),\n",
    "    'breast': BreastMNIST(split='test', transform=None, download=True)\n",
    "}\n",
    "\n",
    "offsets = {'oct': 0, 'pneu': 4, 'retina': 6, 'breast': 11}\n",
    "\n",
    "# Create evaluation dataset and loader\n",
    "eval_dataset = CustomDataset(test_datasets, offsets, transform=transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "print(f\"Eval_loader size:{len(eval_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97242996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:47:29.708649Z",
     "iopub.status.busy": "2025-04-07T09:47:29.708289Z",
     "iopub.status.idle": "2025-04-07T10:25:20.866313Z",
     "shell.execute_reply": "2025-04-07T10:25:20.865198Z"
    },
    "papermill": {
     "duration": 2271.167581,
     "end_time": "2025-04-07T10:25:20.868130",
     "exception": false,
     "start_time": "2025-04-07T09:47:29.700549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 233MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5102\n",
      "Epoch [2/10], Loss: 0.3933\n",
      "Epoch [3/10], Loss: 0.3399\n",
      "Epoch [4/10], Loss: 0.2980\n",
      "Epoch [5/10], Loss: 0.2647\n",
      "Epoch [6/10], Loss: 0.2333\n",
      "Epoch [7/10], Loss: 0.2074\n",
      "Epoch [8/10], Loss: 0.1818\n",
      "Epoch [9/10], Loss: 0.1625\n",
      "Epoch [10/10], Loss: 0.1457\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "# Enable synchronous CUDA errors\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier[6] = nn.Linear(4096, 13)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "# weights_path = '/kaggle/working/vgg16_model.pth'  # Adjust path if needed in Kaggle\n",
    "# state_dict = torch.load(weights_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# 3. Move model to appropriate device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(loader1):  # Replace 'loader' with your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.squeeze(dim=1)\n",
    "\n",
    "        # Validate labels\n",
    "        if labels.max() >= 13 or labels.min() < 0:\n",
    "            print(f\"Batch {i} labels: {labels}\")\n",
    "            raise ValueError(\"Labels must be in range [0, 12]\")\n",
    "\n",
    "        # Ensure correct dtype\n",
    "        labels = labels.long()  # Force to torch.long if not already\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Check for NaN/Inf (optional debugging)\n",
    "        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "            print(f\"Batch {i} outputs contain NaN/Inf: {outputs}\")\n",
    "            raise ValueError(\"Invalid outputs\")\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader1):.4f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save(model.state_dict(), 'vgg16_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516e8590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:25:20.886916Z",
     "iopub.status.busy": "2025-04-07T10:25:20.886669Z",
     "iopub.status.idle": "2025-04-07T11:02:25.147072Z",
     "shell.execute_reply": "2025-04-07T11:02:25.145953Z"
    },
    "papermill": {
     "duration": 2224.271989,
     "end_time": "2025-04-07T11:02:25.149264",
     "exception": false,
     "start_time": "2025-04-07T10:25:20.877275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3988\n",
      "Epoch [2/10], Loss: 0.3263\n",
      "Epoch [3/10], Loss: 0.2800\n",
      "Epoch [4/10], Loss: 0.2432\n",
      "Epoch [5/10], Loss: 0.2086\n",
      "Epoch [6/10], Loss: 0.1824\n",
      "Epoch [7/10], Loss: 0.1569\n",
      "Epoch [8/10], Loss: 0.1362\n",
      "Epoch [9/10], Loss: 0.1196\n",
      "Epoch [10/10], Loss: 0.1094\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(loader2):  # Replace 'loader' with your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.squeeze(dim=1)\n",
    "\n",
    "        # Validate labels\n",
    "        if labels.max() >= 13 or labels.min() < 0:\n",
    "            print(f\"Batch {i} labels: {labels}\")\n",
    "            raise ValueError(\"Labels must be in range [0, 12]\")\n",
    "\n",
    "        # Ensure correct dtype\n",
    "        labels = labels.long()  # Force to torch.long if not already\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Check for NaN/Inf (optional debugging)\n",
    "        if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
    "            print(f\"Batch {i} outputs contain NaN/Inf: {outputs}\")\n",
    "            raise ValueError(\"Invalid outputs\")\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader2):.4f}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save(model.state_dict(), 'vgg16_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de176d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:02:25.175605Z",
     "iopub.status.busy": "2025-04-07T11:02:25.175338Z",
     "iopub.status.idle": "2025-04-07T11:02:25.178481Z",
     "shell.execute_reply": "2025-04-07T11:02:25.177670Z"
    },
    "papermill": {
     "duration": 0.014169,
     "end_time": "2025-04-07T11:02:25.179808",
     "exception": false,
     "start_time": "2025-04-07T11:02:25.165639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.make_archive('zipped_file_name', 'zip', '/kaggle/working/zipped_file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca5256d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:02:25.198471Z",
     "iopub.status.busy": "2025-04-07T11:02:25.198262Z",
     "iopub.status.idle": "2025-04-07T11:02:27.542915Z",
     "shell.execute_reply": "2025-04-07T11:02:27.542243Z"
    },
    "papermill": {
     "duration": 2.355594,
     "end_time": "2025-04-07T11:02:27.544356",
     "exception": false,
     "start_time": "2025-04-07T11:02:25.188762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-3c4f2b6e25e5>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "# Enable synchronous CUDA errors\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier[6] = nn.Linear(4096, 13)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "weights_path = '/kaggle/working/vgg16_model.pth'  # Adjust path if needed in Kaggle\n",
    "state_dict = torch.load(weights_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 3. Move model to appropriate device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b2ac1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:02:27.564099Z",
     "iopub.status.busy": "2025-04-07T11:02:27.563847Z",
     "iopub.status.idle": "2025-04-07T11:02:35.675420Z",
     "shell.execute_reply": "2025-04-07T11:02:35.674540Z"
    },
    "papermill": {
     "duration": 8.122821,
     "end_time": "2025-04-07T11:02:35.676707",
     "exception": false,
     "start_time": "2025-04-07T11:02:27.553886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7069\n",
      "F1 Score (Macro): 0.5443\n",
      "Precision (Macro): 0.6290\n",
      "Recall (Macro): 0.5725\n",
      "AUC (One-vs-Rest, Macro): 0.9544\n",
      "Confusion Matrix:\n",
      "[[234   7   1   8   0   0   0   0   0   0   0   0   0]\n",
      " [ 46 178   1  25   0   0   0   0   0   0   0   0   0]\n",
      " [115  10  22 103   0   0   0   0   0   0   0   0   0]\n",
      " [  8   1   2 239   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0 168  65   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   3 387   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0 152   2   5  11   3   0   0]\n",
      " [  0   0   0   0   0   0  39   1   3   1   2   0   0]\n",
      " [  0   0   0   0   0   0  59   0   6  15  12   0   0]\n",
      " [  0   0   0   0   0   0  31   1   2  21  13   0   0]\n",
      " [  0   0   0   0   0   0  12   0   0   1   7   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0  21  19]\n",
      " [  0   2   0   1   0   0   0   0   0   0   0   6 105]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, device, num_classes=13):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).squeeze()  # Squeeze targets\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Probabilities for AUC\n",
    "            _, predicted = torch.max(outputs, dim=1)  # Predicted classes\n",
    "\n",
    "            # Collect predictions, labels, and probabilities\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # F1 Score (macro average for multi-class)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # Precision and Recall (macro average)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # AUC (one-vs-rest for multi-class)\n",
    "    # Convert labels to one-hot encoding for AUC calculation\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "    except ValueError as e:\n",
    "        print(f\"AUC calculation failed: {e}\")\n",
    "        auc = None\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score (Macro): {f1:.4f}\")\n",
    "    print(f\"Precision (Macro): {precision:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall:.4f}\")\n",
    "    print(f\"AUC (One-vs-Rest, Macro): {auc:.4f}\" if auc is not None else \"AUC: N/A\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    # Return all metrics as a dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model, eval_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4544.79805,
   "end_time": "2025-04-07T11:02:38.250270",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T09:46:53.452220",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
